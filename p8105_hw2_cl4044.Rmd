---
title: "p8105_hw2_cl4044"
author: "Chenxi Liu"
date: "9/26/2020"
output: github_document
---

```{r setup, message=FALSE}
library(tidyverse)
library(readxl)
```

## Problem 1

First, define a path to the dataset. 

```{r}
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```


Read the Mr. Trashwheel dataset. 

```{r}
trashwheel_df = 
	read_xlsx(
		path = path_to_data,
		sheet = "Mr. Trash Wheel",
		range = cell_cols("A:N")) %>% 
	janitor::clean_names() %>% 
	drop_na(dumpster) %>% 
	mutate(
		sports_balls = round(sports_balls),
		sports_balls = as.integer(sports_balls)
	)
```

Read precipitation data! For 2018 and 2017. 

```{r}
precip_2018 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2018 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2018) %>% 
	relocate(year)
precip_2017 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2017 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2017) %>% 
	relocate(year)
```

Now combine annual precipitation dataframes.

```{r}
month_df = 
	tibble(
		month = 1:12,
		month_name = month.name
	)
precip_df = 
	bind_rows(precip_2018, precip_2017)
precip_df =
	left_join(precip_df, month_df, by = "month")
precip_df
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. In this dataset:

* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.

## Problem 2

Read and clean the NYC Transit data. 

```{r, message = FALSE}
transit_df = 
	read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
	janitor::clean_names() %>% 
  select(-division, -staffing, -staff_hours, -ada_notes, -free_crossover, -north_south_street, -east_west_street, -corner, -entrance_latitude, -entrance_longitude, -station_location, -entrance_location, -exit_only ) %>%
  mutate(entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE"),
         vending = recode(vending, "YES" = "TRUE", "NO" = "FALSE"),
         entry = as.logical(entry),
         vending = as.logical(vending)
  )
transit_df
str(transit_df)
```
This dataset contains varibles that are line, station_name, station_latitude, station_longitude, routes served(route1, route2 â€¦), entrance_type, entry, vending, ada. I first performed ``clean_names`` function from the janitor package. This is usually the first function to apply when tidying a dataset. Then I used ``select`` function to remove the unneeded columns. Then I used ``mutate`` function to change "YES" and "NO" to logical values. The dimension of this dataframe is `r nrow(transit_df)` x `r ncol(transit_df)`. These data are not tidy because Route 8-11 are numeric variables. Route 1-11 all has its separate columns.  

Created a subset of the original dataframe. Added a row called ``line_name`` that combines the column ``line`` and ``station_name``.
```{r}
uniq_station_df = unite(transit_df, "line_name", line:station_name, remove = FALSE) %>%
  distinct(line_name, .keep_all = TRUE)
nrow(uniq_station_df)
nrow(filter(uniq_station_df, ada == TRUE))
# proportion of station entrances/exits without vending allow entrance
sum(transit_df$vending == FALSE & transit_df$entry == TRUE)/
  sum(transit_df$vending == FALSE)
```
There are `r nrow(uniq_station_df)` distinct stations. `r nrow(filter(uniq_station_df, ada == TRUE))` are ADA compliant. 

Reformat data so that route number and route name are distinct variables.
```{r}
uniq_station_df[12:16] = sapply(uniq_station_df[12:16], as.character)
uniq_station_df = pivot_longer(
  uniq_station_df,
  route1:route11,
  names_to = "route",
  values_to = "train")

filter_a_df = filter(uniq_station_df, train == "A")
nrow(filter_a_df)
nrow(filter(filter_a_df, ada == TRUE))
```
There are `r nrow(filter_a_df)` rows of distinct stations serve the A train.
There are `r nrow(filter(filter_a_df, ada == TRUE))` of the stations that serve the A train that are ADA compliant.


## Problem 3
Read and clean the data in ``pols-month.csv``.
```{r,message = FALSE}
pols_month_df = 
	read_csv("./data/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, c("year", "month", "day")) %>%
  select(-day) %>%
  mutate(year = as.integer(year)) 

pols_month_df$president = ifelse(pols_month_df$prez_dem == 1, 'dem', 'gop')
pols_month_df = subset(pols_month_df, select = -c(prez_dem, prez_gop)) %>% 
  relocate(year, month, president)

# change month numbers to names
pols_month_df$month = month.name[as.numeric(pols_month_df$month)]
pols_month_df %>% relocate(year, month, president)
pols_month_df
```

Read and clean the data in ``snp.csv``.
```{r, message = FALSE}
snp_df = 
  read_csv(file = "./data/snp.csv") %>% 
  janitor::clean_names()  %>% 
  separate(date, c("month", "day", "year")) %>% 
  subset(select = -day) %>% 
  relocate(year) %>%
  mutate(year = as.integer(year))

# change month numbers to names
snp_df$month = month.name[as.numeric(snp_df$month)]
snp_df
```

Read and clean the data in ``unemployment.csv``.
```{r, message = FALSE}
unemployment_df = 
  read_csv(file = "./data/unemployment.csv") %>% 
  janitor::clean_names() %>%
  mutate( year = as.integer(year))
# change month abbr to full names
colnames(unemployment_df)[2:13] = month.name
unemployment_df = pivot_longer(
  unemployment_df, 
  January:December,
  names_to = "month",
  values_to = "unemployment_rate")
unemployment_df

```

Join the datasets by merging ``snp`` into ``pols``, and merging ``unemployment`` into the result. Key is ``year`` and ``month``. 
```{r}
merged_df = left_join(pols_month_df, snp_df, by = c("year", "month"))
merged_df = left_join(merged_df, unemployment_df,  by = c("year", "month")) %>%
  relocate(year, month, president, close, unemployment_rate)
merged_df
```

``pols_month_df`` contains `r nrow(pols_month_df)` rows X `r ncol(pols_month_df)` columns. The year ranges from 1947 to 2015. The 9 varibles are year, month, president, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem. gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem are related to the number of national politician who are democratic or republican at any given time; the president variable specifies whether the president was democratic or republican.

``snp_df``contains `r nrow(snp_df)` rows X `r ncol(snp_df)` columns.  The year ranges from 1950 to 2015. The 3 variables are year, month, close. The close variable represents the closing market index of the S&P stock index on the that date.

``unemployment_df`` contains `r nrow(unemployment_df)` rows X `r ncol(unemployment_df)` columns. The year ranges from 1948 to 2015. The 3 variables are year, month, and unemployemennt rate. The employment variable represents the unemployement rate in that month of the year.

``merged_df`` contains `r nrow(merged_df)` rows X `r ncol(merged_df)` columns. The year ranges from 1947 to 2015. It joins the three dataframes described above by year and month.



